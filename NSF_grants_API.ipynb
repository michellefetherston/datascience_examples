{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to fix certificate issues\n",
    "\n",
    "#import certifi\n",
    "#import requests\n",
    " \n",
    "#WEB_SITE='http://api.semanticscholar.org/' # Website to test\n",
    "#NM_ROOT_CA='NMProdCACertBundle.pem' # Pem file from above link\n",
    "#try:\n",
    "    #print('Checking connection...')\n",
    "    #test = requests.get(WEB_SITE)\n",
    "    #print('Connection OK.')\n",
    "#except requests.exceptions.SSLError as err:\n",
    "   # print('SSL Error. Adding custom certs to Certifi store...')\n",
    "    #cafile = certifi.where()\n",
    "    #with open(NM_ROOT_CA, 'rb') as infile:\n",
    "        #customca = infile.read()\n",
    "    #with open(cafile, 'ab') as outfile:\n",
    "        #outfile.write(customca)\n",
    "    #print('That might have worked.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://api.nsf.gov/services/v1/awards.json'\n",
    "params = {\n",
    "    'printFields': 'agency,awardeestatecode,coPDPI,startDate,expDate,estimatedTotalAmt,abstractText,awardeeStateCode',\n",
    "    'keyword': 'artificial intelligence', 'offset': 0\n",
    "}\n",
    "\n",
    "df_list = [] # Initialize an empty list to store DataFrames for each page of results\n",
    "\n",
    "while True:\n",
    "    response = requests.get(url, params=params, verify='NMProdCACertBundle.pem')\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()['response']['award']\n",
    "        df = pd.DataFrame.from_records(results)\n",
    "        df_list.append(df)\n",
    "\n",
    "        if len(results) < 25:\n",
    "            # If the page contains less than 25 records, we've reached the end of the results\n",
    "            break\n",
    "        else:\n",
    "            # Otherwise, increase the offset to retrieve the next page of results\n",
    "            params['offset'] += 25\n",
    "    else:\n",
    "        print('Error:', response.status_code)\n",
    "        break\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True) # Combine all DataFrames into a single DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NSF_awards_AI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter down to last 5 years of data\n",
    "from datetime import datetime, timedelta\n",
    "# Convert startDate and expDate columns to datetime type\n",
    "df['startDate'] = pd.to_datetime(df['startDate'])\n",
    "df['expDate'] = pd.to_datetime(df['expDate'])\n",
    "# Filter DataFrame to include rows with a startDate from the last 5 years\n",
    "five_years_ago = datetime.now().date() - timedelta(days=365*5)\n",
    "NSF_last5 = df[df['startDate'] >= pd.to_datetime(five_years_ago)]\n",
    "NSF_last5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5.to_csv('NSF_awards_AI_last5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_WI_last5 = NSF_last5[NSF_last5['awardeeStateCode']=='WI']\n",
    "NSF_WI_last5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_WI_last5.to_csv('WI_NSF_Awards_AI_last5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloading the saved datasets for some analysis and viz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5 = pd.read_csv('NSF_awards_AI_last5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSF_last5.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "NSF_last5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by awardeestatecode and sum the estimatedTotalAmt column, and sort in descending order\n",
    "grouped = NSF_last5.groupby('awardeeStateCode')['estimatedTotalAmt'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Define a formatter function to display values in millions\n",
    "\n",
    "\n",
    "# Create a bar plot of the grouped data\n",
    "plt.figure(figsize=(20, 5)) # Set the figure size to be twice as long\n",
    "plt.bar(grouped.index, grouped.values)\n",
    "\n",
    "# Set the x-axis label rotation to 90 degrees\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Estimated Total Awards by State')\n",
    "plt.xlabel('Awardee State Code')\n",
    "plt.ylabel('Estimated Total Awards (in hundreds of millions)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows where awardeeStateCode = 'CA'\n",
    "CA_df = NSF_last5[NSF_last5['awardeeStateCode'] == 'CA']\n",
    "\n",
    "# Compute the sum of estimatedTotalAmt for the filtered DataFrame\n",
    "total_amt_CA = CA_df['estimatedTotalAmt'].sum()\n",
    "\n",
    "print(f'The total estimated award amount for awardeeStateCode CA is ${total_amt_CA:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
